<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The State of AI Bias: A Comprehensive Analysis</title>
    <link rel="icon" href="https://pbs.twimg.com/profile_images/1944657556875657216/mBLyFA8n_400x400.jpg">
    <!-- Chosen Palette: Mira Aesthetic (Monochromatic + Blue Accent) -->
    <!-- Application Structure Plan: The webpage is designed as a professional, single-page whitepaper. It follows a logical narrative flow, beginning with a stark, minimalist hero section stating the core thesis. It then uses a clean, card-based layout to present the key statistics from the executive summary. The core of the paper—the domain-specific bias cases—is organized into an elegant tabbed interface to keep the layout uncluttered. This is followed by a data visualization section with charts styled in the monochromatic theme. The Mira solution is explained via a minimalist, technical-style flowchart. The page concludes with a clean timeline for the regulatory landscape and a simple, scannable list of recommendations. This structure prioritizes clarity, authority, and a premium, tech-forward feel, aligning perfectly with the Mira Network's brand aesthetic. -->
    <!-- Visualization & Content Choices: 
        - Key Statistics: Goal: Inform. Viz: Minimalist cards with large numbers. Justification: Provides a high-impact, scannable overview of the core problem metrics. Method: HTML/CSS.
        - Bias Prevalence Chart: Goal: Compare. Viz: Horizontal Bar Chart. Justification: Effectively compares bias types with a clean, professional look. Method: Chart.js/Canvas, styled monochromatically.
        - Accuracy Simulator: Goal: Interact/Educate. Viz: A slider connected to dynamic text outputs. Justification: Allows users to tangibly feel the impact of adding models to a consensus. Method: JavaScript.
        - Consensus Demonstration: Goal: Explain a process. Viz: An interactive simulation where users input a query and see models "vote". Justification: Actively demonstrates the core value of Mira's solution. Method: JavaScript.
        - Bias Risk Calculator: Goal: Interact/Educate. Viz: A form with sliders and dropdowns that calculates a risk score. Justification: Engages the user in assessing risk factors, making the concepts more concrete. Method: JavaScript.
        - Gemini Q&A: Goal: Engage/Educate. Viz: A simple text input form that opens a modal with an AI-generated answer. Justification: Provides a high-tech, personalized way for users to explore topics of interest. Method: Gemini API Call.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #FFFFFF;
            color: #111827;
        }
        .accent-blue { color: #2563EB; }
        .bg-accent-blue { background-color: #2563EB; }
        .border-accent-blue { border-color: #2563EB; }
        .nav-link {
            position: relative;
            transition: color 0.2s ease-in-out;
        }
        .nav-link:after {
            content: '';
            position: absolute;
            width: 0;
            height: 2px;
            bottom: -4px;
            left: 0;
            background-color: #2563EB;
            transition: width 0.2s ease-in-out;
        }
        .nav-link:hover:after, .nav-link.active:after {
            width: 100%;
        }
        .tab-button {
            transition: all 0.2s ease-in-out;
        }
        .tab-button.active {
            color: #2563EB;
            border-bottom-color: #2563EB;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            height: 400px;
            max-height: 450px;
        }
        @media (max-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .processing-dot {
            animation: bounce 1.4s infinite ease-in-out both;
        }
        .processing-dot:nth-child(1) { animation-delay: -0.32s; }
        .processing-dot:nth-child(2) { animation-delay: -0.16s; }
        @keyframes bounce {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1.0); }
        }
        #gemini-modal {
            transition: opacity 0.3s ease-in-out;
        }
        .gemini-modal-content {
            transition: transform 0.3s ease-in-out;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #2563EB;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="antialiased">

    <header class="bg-white/80 backdrop-blur-sm sticky top-0 z-50 border-b border-gray-200">
        <nav class="container mx-auto px-6 py-4 flex justify-between items-center">
            <a href="#home" class="flex items-center gap-3">
                <img src="https://pbs.twimg.com/profile_images/1944657556875657216/mBLyFA8n_400x400.jpg" alt="Mira Network Logo" class="h-8 w-8">
                <span class="text-xl font-bold tracking-wide">Mira Network</span>
            </a>
            <div class="hidden md:flex items-center gap-8">
                <a href="#problem" class="nav-link text-sm font-medium text-gray-600 hover:text-gray-900">The Problem</a>
                <a href="#solution" class="nav-link text-sm font-medium text-gray-600 hover:text-gray-900">The Solution</a>
                <a href="#data" class="nav-link text-sm font-medium text-gray-600 hover:text-gray-900">The Data</a>
                <a href="#timeline" class="nav-link text-sm font-medium text-gray-600 hover:text-gray-900">Regulation</a>
            </div>
        </nav>
    </header>

    <main class="container mx-auto px-6">
        <section id="home" class="text-center py-24 md:py-32">
            <h1 class="text-4xl md:text-6xl font-extrabold tracking-tighter text-gray-900">The State of AI Bias</h1>
            <p class="mt-6 max-w-3xl mx-auto text-lg md:text-xl text-gray-600">
                A comprehensive analysis of algorithmic harm and the consensus-based solution for building verifiably fair AI systems.
            </p>
        </section>

        <section id="stats" class="py-16 grid grid-cols-1 md:grid-cols-3 gap-8 text-center border-t border-b border-gray-200">
            <div>
                <p class="text-5xl font-bold accent-blue">44%</p>
                <p class="mt-2 font-semibold">Gender Bias Prevalence</p>
                <p class="text-sm text-gray-500">in a study of 133 enterprise AI systems.</p>
            </div>
            <div>
                <p class="text-5xl font-bold accent-blue">$3.1T</p>
                <p class="mt-2 font-semibold">Annual Cost of Poor Data</p>
                <p class="text-sm text-gray-500">to the U.S. economy, a root cause of bias.</p>
            </div>
            <div>
                <p class="text-5xl font-bold accent-blue">95.6%</p>
                <p class="mt-2 font-semibold">Precision with Consensus</p>
                <p class="text-sm text-gray-500">achieved with Mira's 3-model verification.</p>
            </div>
        </section>

        <section id="problem" class="py-20 md:py-24">
            <div class="text-center max-w-3xl mx-auto">
                <h2 class="text-3xl md:text-4xl font-bold tracking-tight">Bias by Domain: A Cross-Sector Analysis</h2>
                <p class="mt-4 text-gray-600">Algorithmic bias is not a monolithic phenomenon. Its manifestations and consequences are highly context-dependent, shaped by the data and objectives of the domain in which it is deployed.</p>
            </div>

            <div class="mt-12 max-w-5xl mx-auto">
                <div class="flex border-b border-gray-200">
                    <button class="tab-button active flex-1 py-3 text-sm font-semibold border-b-2 border-transparent" data-tab="americas">US & EU</button>
                    <button class="tab-button flex-1 py-3 text-sm font-semibold border-b-2 border-transparent" data-tab="global">Global Perspective</button>
                </div>
                <div id="tab-content-main" class="pt-8">
                    <div class="tab-pane" id="americas">
                        <div class="flex border-b border-gray-200">
                            <button class="tab-button-inner active flex-1 py-3 text-sm font-semibold border-b-2 border-transparent" data-tab="healthcare">Healthcare</button>
                            <button class="tab-button-inner flex-1 py-3 text-sm font-semibold border-b-2 border-transparent" data-tab="justice">Criminal Justice</button>
                            <button class="tab-button-inner flex-1 py-3 text-sm font-semibold border-b-2 border-transparent" data-tab="employment">Employment</button>
                            <button class="tab-button-inner flex-1 py-3 text-sm font-semibold border-b-2 border-transparent" data-tab="finance">Financial Services</button>
                        </div>
                        <div id="tab-content-inner" class="pt-8">
                            <div class="tab-pane-inner" id="healthcare">
                                <h3 class="text-xl font-bold mb-2">Healthcare: The Algorithmic Perpetuation of Health Disparities</h3>
                                <p class="text-gray-600">A commercial algorithm used by U.S. hospitals to identify high-risk patients used healthcare <span class="font-semibold text-gray-800">cost as a proxy for need</span>. Because Black patients generate lower costs at the same level of illness, the algorithm systematically underestimated their health needs, reducing access to critical care programs by over 50%.</p>
                            </div>
                            <div class="tab-pane-inner hidden" id="justice">
                                <h3 class="text-xl font-bold mb-2">Criminal Justice: Encoding Inequity in Predictive Systems</h3>
                                <p class="text-gray-600">The COMPAS recidivism risk tool was found to be <span class="font-semibold text-gray-800">twice as likely to falsely label Black defendants as high-risk</span> for future crimes compared to White defendants. This was due to training on historically biased arrest and conviction data, automating discrimination in the courtroom.</p>
                            </div>
                            <div class="tab-pane-inner hidden" id="employment">
                                <h3 class="text-xl font-bold mb-2">Employment: Automating Discrimination at Scale</h3>
                                <p class="text-gray-600">Amazon's experimental AI hiring tool, trained on a decade of its own male-dominated resume data, learned to <span class="font-semibold text-gray-800">penalize resumes containing the word "women's"</span> and downgrade graduates of all-women's colleges. The bias was so ingrained the project was scrapped.</p>
                            </div>
                            <div class="tab-pane-inner hidden" id="finance">
                                <h3 class="text-xl font-bold mb-2">Financial Services: Modern Redlining in the Digital Age</h3>
                                <p class="text-gray-600">Lending algorithms were found to charge Black and Latino borrowers <span class="font-semibold text-gray-800">up to $500 million more in annual interest</span> by using "low-shopping behavior" as a proxy for minority status, allowing the algorithms to engage in profitable, discriminatory price-gouging.</p>
                            </div>
                        </div>
                    </div>
                    <div class="tab-pane hidden" id="global">
                        <h3 class="text-xl font-bold mb-2">Global Perspective: Bias Beyond the West</h3>
                        <p class="text-gray-600 mb-4">AI bias is a global issue, but its manifestations are shaped by local cultural and historical contexts. Datasets are often dominated by Western data, leading to poor performance and harmful stereotypes for other populations.</p>
                        <ul class="list-disc list-inside space-y-2 text-gray-600">
                            <li><span class="font-semibold text-gray-800">Asia:</span> Facial recognition systems in China have been criticized for lower accuracy on ethnic minorities like Uyghurs. In India, caste bias can be encoded in hiring and lending algorithms trained on data reflecting historical social stratification.</li>
                            <li><span class="font-semibold text-gray-800">Africa:</span> Language models often perform poorly on the continent's thousands of low-resource languages, limiting access to information. AI-driven agricultural tools trained on data from other continents may fail to account for local soil conditions and crop types.</li>
                            <li><span class="font-semibold text-gray-800">Latin America:</span> Predictive policing models imported from the U.S. can amplify existing biases against indigenous and Afro-descendant communities, failing to account for unique local socio-economic factors.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        
        <section id="solution" class="py-20 md:py-24 bg-gray-900 text-white rounded-lg">
             <div class="text-center max-w-3xl mx-auto">
                <h2 class="text-3xl md:text-4xl font-bold tracking-tight">Interactive Consensus Demonstration</h2>
                <p class="mt-4 text-gray-400">See how Mira Network verifies decisions. Enter a sample query and run the simulation to observe how a consensus of independent models catches and filters out biased outliers.</p>
            </div>
            <div class="mt-12 max-w-4xl mx-auto bg-gray-800 p-8 rounded-lg border border-gray-700">
                <div class="flex flex-col sm:flex-row gap-4">
                    <input type="text" id="demo-input" class="w-full bg-gray-700 text-white px-4 py-2 border border-gray-600 rounded-md focus:ring-2 focus:ring-accent-blue focus:outline-none" placeholder="e.g., 'Review loan application for Jane Doe'">
                    <button id="run-demo-btn" class="bg-accent-blue text-white font-semibold py-2 px-6 rounded-md hover:bg-blue-700 transition whitespace-nowrap">Run Simulation</button>
                </div>
                <div id="demo-results" class="mt-8 grid grid-cols-1 md:grid-cols-3 gap-6 text-center hidden">
                    <div class="border border-gray-700 p-4 rounded-lg">
                        <h4 class="font-semibold">Model A</h4>
                        <div id="model-a-status" class="mt-2 text-sm text-gray-400">Awaiting Input...</div>
                    </div>
                    <div class="border border-gray-700 p-4 rounded-lg">
                        <h4 class="font-semibold">Model B</h4>
                        <div id="model-b-status" class="mt-2 text-sm text-gray-400">Awaiting Input...</div>
                    </div>
                    <div class="border border-gray-700 p-4 rounded-lg">
                        <h4 class="font-semibold">Model C (Biased)</h4>
                        <div id="model-c-status" class="mt-2 text-sm text-gray-400">Awaiting Input...</div>
                    </div>
                </div>
                <div id="consensus-result" class="mt-6 text-center hidden">
                    <h3 class="text-xl font-bold"></h3>
                    <p class="text-gray-400"></p>
                </div>
            </div>
        </section>

        <section id="data" class="py-20 md:py-24">
            <div class="text-center max-w-3xl mx-auto">
                <h2 class="text-3xl md:text-4xl font-bold tracking-tight">Interactive Simulation: The Power of Consensus</h2>
                <p class="mt-4 text-gray-600">A single AI model is inherently fallible. Use the slider below to see how adding independent models to a consensus network dramatically increases decision precision and reduces the error rate, transforming a risky tool into a verifiable system.</p>
            </div>
            <div class="mt-12 max-w-4xl mx-auto bg-white p-8 rounded-lg border border-gray-200">
                <div class="flex flex-col md:flex-row justify-between items-center gap-8">
                    <div class="w-full md:w-1/2">
                        <label for="model-slider" class="block text-center font-semibold mb-2">Number of Models in Consensus: <span id="slider-value" class="font-bold text-accent-blue text-lg">1</span></label>
                        <input id="model-slider" type="range" min="1" max="5" value="1" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
                    </div>
                    <div class="text-center">
                        <p class="text-gray-500 text-sm">Verified Precision</p>
                        <p id="precision-display" class="text-5xl font-extrabold text-gray-900">73.1%</p>
                    </div>
                    <div class="text-center">
                        <p class="text-gray-500 text-sm">Error Rate</p>
                        <p id="error-display" class="text-5xl font-extrabold text-red-500">26.9%</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="risk-calculator" class="py-20 md:py-24 bg-gray-50 rounded-lg">
            <div class="text-center max-w-3xl mx-auto">
                <h2 class="text-3xl md:text-4xl font-bold tracking-tight">AI Bias Risk Calculator</h2>
                <p class="mt-4 text-gray-600">Assess the potential bias risk of a hypothetical AI system based on key factors. Adjust the parameters to see how they influence the overall risk score.</p>
            </div>
            <div class="mt-12 max-w-4xl mx-auto bg-white p-8 rounded-lg border border-gray-200 grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
                <div class="space-y-6">
                    <div>
                        <label for="risk-industry" class="block font-semibold mb-2">Industry / Domain:</label>
                        <select id="risk-industry" class="w-full p-2 border border-gray-300 rounded-md">
                            <option value="30">Healthcare</option>
                            <option value="30">Criminal Justice</option>
                            <option value="30">Financial Services</option>
                            <option value="20">Employment / Hiring</option>
                            <option value="10">Content Recommendation</option>
                        </select>
                    </div>
                    <div>
                        <label for="risk-data-diversity" class="block font-semibold mb-2">Training Data Diversity: <span id="data-diversity-label" class="font-normal text-gray-600"></span></label>
                        <input id="risk-data-diversity" type="range" min="0" max="40" value="20" class="w-full">
                    </div>
                    <div>
                        <label for="risk-transparency" class="block font-semibold mb-2">Model Transparency: <span id="transparency-label" class="font-normal text-gray-600"></span></label>
                        <input id="risk-transparency" type="range" min="0" max="30" value="15" class="w-full">
                    </div>
                </div>
                <div class="text-center p-6 bg-gray-100 rounded-lg">
                    <p class="text-gray-500 font-semibold">Calculated Bias Risk</p>
                    <p id="risk-score-display" class="text-7xl font-extrabold my-4">0%</p>
                    <p id="risk-level-display" class="text-xl font-bold"></p>
                    <p id="risk-feedback" class="text-sm text-gray-600 mt-2"></p>
                </div>
            </div>
        </section>

        <section id="gemini-qna" class="py-20 md:py-24">
            <div class="text-center max-w-3xl mx-auto">
                <h2 class="text-3xl md:text-4xl font-bold tracking-tight">Ask an AI Ethicist</h2>
                <p class="mt-4 text-gray-600">Have a question about AI bias, fairness, or the Mira Network? Get an instant, detailed explanation from our Gemini-powered expert.</p>
            </div>
            <div class="mt-12 max-w-3xl mx-auto">
                <div class="bg-white p-8 rounded-lg border border-gray-200">
                    <textarea id="gemini-prompt" class="w-full p-3 border border-gray-300 rounded-md focus:ring-2 focus:ring-accent-blue focus:outline-none" rows="3" placeholder="e.g., How does consensus verification differ from other fairness methods?"></textarea>
                    <button id="gemini-submit" class="mt-4 w-full bg-accent-blue text-white font-semibold py-3 px-6 rounded-md hover:bg-blue-700 transition">
                        Get Answer
                    </button>
                </div>
            </div>
        </section>

        <section id="timeline" class="py-20 md:py-24">
            <div class="text-center max-w-3xl mx-auto">
                <h2 class="text-3xl md:text-4xl font-bold tracking-tight">The Regulatory Landscape</h2>
                <p class="mt-4 text-gray-600">A global wave of binding legislation is shifting the paradigm from voluntary ethics to mandatory, verifiable proof of fairness.</p>
            </div>
            <div class="mt-16 max-w-2xl mx-auto">
                <div class="relative pl-8 py-4 border-l-2 border-gray-200">
                    <div class="absolute -left-2 top-4 w-4 h-4 bg-accent-blue rounded-full border-4 border-white"></div>
                    <p class="text-sm font-semibold text-gray-500">2018</p>
                    <h4 class="font-bold">"Gender Shades" Study</h4>
                    <p class="text-sm text-gray-600">MIT research reveals massive accuracy disparities in commercial facial recognition.</p>
                </div>
                <div class="relative pl-8 py-4 border-l-2 border-gray-200">
                    <div class="absolute -left-2 top-4 w-4 h-4 bg-accent-blue rounded-full border-4 border-white"></div>
                    <p class="text-sm font-semibold text-gray-500">2021</p>
                    <h4 class="font-bold">EU Proposes AI Act</h4>
                    <p class="text-sm text-gray-600">The first major legal framework for AI is introduced, mandating bias checks.</p>
                </div>
                <div class="relative pl-8 py-4 border-l-2 border-gray-200">
                    <div class="absolute -left-2 top-4 w-4 h-4 bg-accent-blue rounded-full border-4 border-white"></div>
                    <p class="text-sm font-semibold text-gray-500">2023</p>
                    <h4 class="font-bold">NYC Local Law 144 Takes Effect</h4>
                    <p class="text-sm text-gray-600">Mandates public, independent bias audits for automated hiring tools.</p>
                </div>
                <div class="relative pl-8 py-4 border-l-2 border-gray-200">
                    <div class="absolute -left-2 top-4 w-4 h-4 bg-accent-blue rounded-full border-4 border-white"></div>
                    <p class="text-sm font-semibold text-gray-500">2024</p>
                    <h4 class="font-bold">EU AI Act Becomes Law</h4>
                    <p class="text-sm text-gray-600">Sets a de facto global standard for AI regulation and compliance.</p>
                </div>
            </div>
        </section>
    </main>

    <footer class="bg-gray-900 text-white">
        <div class="container mx-auto px-6 py-8 text-center">
            <p class="text-sm text-gray-400">The State of AI Bias: A Comprehensive Analysis</p>
            <p class="text-xs text-gray-500 mt-2">Presented by Mira Network</p>
        </div>
    </footer>

    <!-- Gemini Modal -->
    <div id="gemini-modal" class="hidden fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center z-50 p-4 opacity-0">
        <div class="gemini-modal-content bg-white rounded-lg shadow-xl w-full max-w-2xl max-h-[90vh] overflow-y-auto transform scale-95">
            <div class="p-6">
                <div class="flex justify-between items-start">
                    <h3 id="gemini-modal-title" class="text-2xl font-bold text-gray-800"></h3>
                    <button id="gemini-modal-close" class="text-gray-400 hover:text-gray-600 text-3xl leading-none">&times;</button>
                </div>
                <div id="gemini-modal-body" class="mt-4 text-gray-600 prose max-w-none">
                    <!-- Content will be injected here -->
                </div>
            </div>
        </div>
    </div>

<script>
    document.addEventListener('DOMContentLoaded', () => {
        // Main Tabs
        const mainTabButtons = document.querySelectorAll('.tab-button');
        const mainTabPanes = document.querySelectorAll('.tab-pane');
        mainTabButtons.forEach(button => {
            button.addEventListener('click', () => {
                mainTabButtons.forEach(btn => btn.classList.remove('active'));
                button.classList.add('active');
                const tabId = button.dataset.tab;
                mainTabPanes.forEach(pane => {
                    pane.id === tabId ? pane.classList.remove('hidden') : pane.classList.add('hidden');
                });
            });
        });

        // Inner Tabs
        const innerTabButtons = document.querySelectorAll('.tab-button-inner');
        const innerTabPanes = document.querySelectorAll('.tab-pane-inner');
        innerTabButtons.forEach(button => {
            button.addEventListener('click', () => {
                innerTabButtons.forEach(btn => btn.classList.remove('active'));
                button.classList.add('active');
                const tabId = button.dataset.tab;
                innerTabPanes.forEach(pane => {
                    pane.id === tabId ? pane.classList.remove('hidden') : pane.classList.add('hidden');
                });
            });
        });
        document.querySelector('.tab-button-inner[data-tab="healthcare"]').click();
        document.querySelector('.tab-button[data-tab="americas"]').click();

        // Interactive Accuracy Simulator
        const slider = document.getElementById('model-slider');
        const sliderValueDisplay = document.getElementById('slider-value');
        const precisionDisplay = document.getElementById('precision-display');
        const errorDisplay = document.getElementById('error-display');

        const simulationData = {
            1: { precision: 73.1, color: '#EF4444' },
            2: { precision: 93.9, color: '#F59E0B' },
            3: { precision: 95.6, color: '#10B981' },
            4: { precision: 97.2, color: '#2563EB' },
            5: { precision: 98.5, color: '#2563EB' }
        };

        slider.addEventListener('input', (event) => {
            const modelCount = event.target.value;
            const data = simulationData[modelCount];
            const errorRate = (100 - data.precision).toFixed(1);

            sliderValueDisplay.textContent = modelCount;
            precisionDisplay.textContent = `${data.precision}%`;
            errorDisplay.textContent = `${errorRate}%`;
            
            precisionDisplay.style.color = data.color;
            errorDisplay.style.color = modelCount > 1 ? '#10B981' : '#EF4444';
        });
        slider.dispatchEvent(new Event('input'));

        // Consensus Demo
        const runDemoBtn = document.getElementById('run-demo-btn');
        const demoInput = document.getElementById('demo-input');
        const demoResults = document.getElementById('demo-results');
        const consensusResult = document.getElementById('consensus-result');
        const modelStatuses = {
            a: document.getElementById('model-a-status'),
            b: document.getElementById('model-b-status'),
            c: document.getElementById('model-c-status')
        };
        
        const setStatus = (el, text, colorClass = 'text-gray-400') => {
            el.innerHTML = `<span class="font-bold text-lg ${colorClass}">${text}</span>`;
        };

        const setProcessing = (el) => {
            el.innerHTML = `<div class="flex justify-center items-center space-x-1 h-6">
                <div class="w-2 h-2 bg-blue-400 rounded-full processing-dot"></div>
                <div class="w-2 h-2 bg-blue-400 rounded-full processing-dot"></div>
                <div class="w-2 h-2 bg-blue-400 rounded-full processing-dot"></div>
            </div>`;
        };

        runDemoBtn.addEventListener('click', () => {
            if (!demoInput.value) {
                alert('Please enter a sample query.');
                return;
            }
            demoResults.classList.remove('hidden');
            consensusResult.classList.add('hidden');

            Object.values(modelStatuses).forEach(setProcessing);

            setTimeout(() => {
                const decisionA = Math.random() > 0.1 ? 'Approve' : 'Deny'; // 90% chance of fair
                const decisionB = Math.random() > 0.1 ? 'Approve' : 'Deny'; // 90% chance of fair
                const decisionC = Math.random() > 0.6 ? 'Approve' : 'Deny'; // 40% chance of fair (biased model)
                
                setStatus(modelStatuses.a, decisionA, decisionA === 'Approve' ? 'text-green-400' : 'text-red-400');
                setStatus(modelStatuses.b, decisionB, decisionB === 'Approve' ? 'text-green-400' : 'text-red-400');
                setStatus(modelStatuses.c, decisionC, decisionC === 'Approve' ? 'text-green-400' : 'text-red-400');

                consensusResult.classList.remove('hidden');
                const consensusTitle = consensusResult.querySelector('h3');
                const consensusText = consensusResult.querySelector('p');

                if (decisionA === decisionB && decisionA === decisionC) {
                    consensusTitle.textContent = '✅ Consensus Reached';
                    consensusTitle.className = 'text-xl font-bold text-green-400';
                    consensusText.textContent = `All models agree. The decision is verified as '${decisionA}'.`;
                } else if (decisionA === decisionB) {
                    consensusTitle.textContent = '❌ Consensus Failed: Outlier Detected';
                    consensusTitle.className = 'text-xl font-bold text-yellow-400';
                    consensusText.textContent = `Models A and B agree on '${decisionA}', but the biased Model C dissents. The decision is flagged for human review.`;
                } else {
                     consensusTitle.textContent = '❌ Consensus Failed: No Agreement';
                    consensusTitle.className = 'text-xl font-bold text-red-400';
                    consensusText.textContent = `The models could not reach a consensus. The decision is flagged for human review.`;
                }
            }, 1500);
        });

        // AI Bias Risk Calculator
        const riskIndustry = document.getElementById('risk-industry');
        const riskDataDiversity = document.getElementById('risk-data-diversity');
        const riskTransparency = document.getElementById('risk-transparency');
        const dataDiversityLabel = document.getElementById('data-diversity-label');
        const transparencyLabel = document.getElementById('transparency-label');
        const riskScoreDisplay = document.getElementById('risk-score-display');
        const riskLevelDisplay = document.getElementById('risk-level-display');
        const riskFeedback = document.getElementById('risk-feedback');

        const diversityLabels = { 0: 'Very Low', 10: 'Low', 20: 'Moderate', 30: 'High', 40: 'Very High' };
        const transparencyLabels = { 0: 'Black Box', 10: 'Partially Explainable', 20: 'Mostly Transparent', 30: 'Fully Auditable' };

        function updateRiskCalculator() {
            const industryRisk = parseInt(riskIndustry.value);
            const dataDiversityRisk = 40 - parseInt(riskDataDiversity.value); // Higher value is better, so we invert
            const transparencyRisk = 30 - parseInt(riskTransparency.value); // Higher value is better, so we invert

            const totalRisk = industryRisk + dataDiversityRisk + transparencyRisk;
            
            riskScoreDisplay.textContent = `${totalRisk}%`;
            dataDiversityLabel.textContent = diversityLabels[riskDataDiversity.value];
            transparencyLabel.textContent = transparencyLabels[riskTransparency.value];

            if (totalRisk >= 70) {
                riskLevelDisplay.textContent = 'High Risk';
                riskLevelDisplay.className = 'text-xl font-bold text-red-500';
                riskFeedback.textContent = 'Significant potential for biased outcomes. Requires robust mitigation and verification.';
            } else if (totalRisk >= 40) {
                riskLevelDisplay.textContent = 'Medium Risk';
                riskLevelDisplay.className = 'text-xl font-bold text-yellow-500';
                riskFeedback.textContent = 'Potential for bias exists. Careful monitoring and fairness audits are recommended.';
            } else {
                riskLevelDisplay.textContent = 'Low Risk';
                riskLevelDisplay.className = 'text-xl font-bold text-green-500';
                riskFeedback.textContent = 'Lower potential for bias, but continuous monitoring is still essential.';
            }
        }

        riskIndustry.addEventListener('input', updateRiskCalculator);
        riskDataDiversity.addEventListener('input', updateRiskCalculator);
        riskTransparency.addEventListener('input', updateRiskCalculator);
        updateRiskCalculator();
        
        // Gemini Q&A
        const geminiModal = document.getElementById('gemini-modal');
        const geminiModalTitle = document.getElementById('gemini-modal-title');
        const geminiModalBody = document.getElementById('gemini-modal-body');
        const geminiModalClose = document.getElementById('gemini-modal-close');
        const geminiSubmitBtn = document.getElementById('gemini-submit');
        const geminiPrompt = document.getElementById('gemini-prompt');

        const showGeminiModal = (title, content) => {
            geminiModalTitle.textContent = title;
            geminiModalBody.innerHTML = content;
            geminiModal.classList.remove('hidden');
            setTimeout(() => {
                geminiModal.classList.remove('opacity-0');
                geminiModal.querySelector('.gemini-modal-content').classList.remove('scale-95');
            }, 10);
        };

        const hideGeminiModal = () => {
            geminiModal.classList.add('opacity-0');
            geminiModal.querySelector('.gemini-modal-content').classList.add('scale-95');
            setTimeout(() => {
                geminiModal.classList.add('hidden');
            }, 300);
        };

        geminiModalClose.addEventListener('click', hideGeminiModal);
        geminiModal.addEventListener('click', (e) => {
            if (e.target === geminiModal) {
                hideGeminiModal();
            }
        });

        const callGeminiAPI = async (prompt) => {
            const apiKey = "AIzaSyBtdxAevjwr66TCGMzIk8Jn8l5NbAiLRf0";
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;
            
            const payload = {
                contents: [{ parts: [{ text: prompt }] }]
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) throw new Error(`API request failed with status ${response.status}`);
                const result = await response.json();
                if (result.candidates && result.candidates.length > 0) {
                    return result.candidates[0].content.parts[0].text;
                }
                return "Error: Could not retrieve a valid response.";
            } catch (error) {
                console.error("Error calling Gemini API:", error);
                return `Error: Could not connect to the AI model. Details: ${error.message}`;
            }
        };

        geminiSubmitBtn.addEventListener('click', async () => {
            const userQuery = geminiPrompt.value;
            if (!userQuery) {
                alert('Please enter a question.');
                return;
            }

            const fullPrompt = `
                As an AI ethics expert, please answer the following question based on the principles of algorithmic fairness and the benefits of consensus verification as described in the Mira Network research paper. Provide a clear, concise, and authoritative answer.
                Question: "${userQuery}"
            `;
            
            showGeminiModal('AI Ethicist Response', '<div class="flex justify-center items-center p-8"><div class="loader"></div></div>');
            const result = await callGeminiAPI(fullPrompt);
            let htmlResult = result
                .replace(/### (.*)/g, '<h4 class="text-lg font-bold text-gray-800 mt-4 mb-2">$1</h4>')
                .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                .replace(/\n/g, '<br>');

            showGeminiModal('AI Ethicist Response', htmlResult);
        });

    });
</script>

</body>
</html>
